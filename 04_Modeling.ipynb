{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0519af",
   "metadata": {},
   "source": [
    "### Stoke Prediction Dataset \n",
    "# Modeling\n",
    "\n",
    "Data source: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset <br>\n",
    "Data updated date: 2021-01-26\n",
    "\n",
    "#### Supervised Learning: Classification model to predict a binary outcome\n",
    "Outcome:\n",
    "- 0: no stroke\n",
    "- 1: stroke\n",
    "\n",
    "Here are the different types of learning that we will implore for out prediction.\n",
    "- Decision Tree\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "\n",
    "Model Evaluation:\n",
    "- Confusion Matrix: Maximize True Positive rate, minimize False Nagative rate.\n",
    "- Recall for stroke\n",
    "![title](img/ConfusionMatrix.ppm)\n",
    "- Balanced accuracy\n",
    "![title](img/Balanced-accuracy-formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3668a5",
   "metadata": {},
   "source": [
    "# 0. Sourcing, Loading, and Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa96cd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import packagas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# make notebook full width for better viewing\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8a4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "X_train = pd.read_csv('data/X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('data/X_test.csv', index_col=0)\n",
    "\n",
    "y_train = pd.read_csv('data/y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38953e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an evaluation model that print its performance\n",
    "\n",
    "def evaluation(y_pred, y_test):\n",
    "    # confusion matrix\n",
    "    tp, fn, fp, tn = confusion_matrix(y_test,y_pred,labels=[1,0]).reshape(-1)\n",
    "    print('Outcome values : tp:{}, fn:{}, fn:{}, tn:{}'.format(tp, fn, fp, tn))\n",
    "\n",
    "    # model evaluation metrics - recall\n",
    "    print('\\nRecall score for \"No Stroke\": ' , round(metrics.recall_score(y_test,y_pred, pos_label = 0),2))\n",
    "    print('Recall score for \"Stroke\": ' , round(metrics.recall_score(y_test,y_pred, pos_label = 1), 2))\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "    matrix = classification_report(y_test, y_pred, target_names=['No Stroke', 'Stroke'])\n",
    "    print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "    # model evaluation metrics - accuracy\n",
    "    print(\"Balanced accuracy:\", round(metrics.balanced_accuracy_score(y_test,y_pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3a8ec",
   "metadata": {},
   "source": [
    "# 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ee02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# fit the data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d52b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : tp:11, fn:52, fn:73, tn:1397\n",
      "\n",
      "Recall score for \"No Stroke\":  0.95\n",
      "Recall score for \"Stroke\":  0.17\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.96      0.95      0.96      1470\n",
      "      Stroke       0.13      0.17      0.15        63\n",
      "\n",
      "    accuracy                           0.92      1533\n",
      "   macro avg       0.55      0.56      0.55      1533\n",
      "weighted avg       0.93      0.92      0.92      1533\n",
      "\n",
      "Balanced accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "# print model performance\n",
    "evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a766e",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a0036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#import model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create the model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5365fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : tp:0, fn:63, fn:0, tn:1470\n",
      "\n",
      "Recall score for \"No Stroke\":  1.0\n",
      "Recall score for \"Stroke\":  0.0\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.96      1.00      0.98      1470\n",
      "      Stroke       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.96      1533\n",
      "   macro avg       0.48      0.50      0.49      1533\n",
      "weighted avg       0.92      0.96      0.94      1533\n",
      "\n",
      "Balanced accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print model performance\n",
    "evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd532cdf",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20ec4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b01d7a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : tp:0, fn:63, fn:3, tn:1467\n",
      "\n",
      "Recall score for \"No Stroke\":  1.0\n",
      "Recall score for \"Stroke\":  0.0\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.96      1.00      0.98      1470\n",
      "      Stroke       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.96      1533\n",
      "   macro avg       0.48      0.50      0.49      1533\n",
      "weighted avg       0.92      0.96      0.94      1533\n",
      "\n",
      "Balanced accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# print model performance\n",
    "evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ac62fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "sample_size = ceil(len(y_test)/2)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd92bc",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "Decision Tree, Logistic Regression, and Random Forest all performed badly on this dataset by default, most likely due to the nature of imbalanced dataset.\n",
    "\n",
    "If we make a rough guess that half of the people will get stroke, we will get the following confusion matrix:<br>\n",
    "tp: 28<br>\n",
    "fp: 739 <br>\n",
    "tn: 732<br>\n",
    "fn: 35<br>\n",
    "\n",
    "making the recall score 0.44, higher than these models above. (Decision tree: 0.17; Logistic regression: 0, Random forest: 0)\n",
    "\n",
    "### Optimization suggestion.\n",
    "\n",
    "1. Implement SMOTE for imbalanced data (oversample the stroke data) and undersample the non-stroke data.<br>\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n",
    "2. Use Cross Validation, Grid Search, and Random Search to tune the hyperparameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
